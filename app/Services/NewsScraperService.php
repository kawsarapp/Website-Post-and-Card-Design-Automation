<?php

namespace App\Services;

use Illuminate\Support\Facades\Http;
use Illuminate\Support\Facades\Log;

// ğŸ”¥ Traits Import
use App\Traits\ScraperEnginesTrait;
use App\Traits\ScraperHtmlParserTrait;
use App\Traits\ScraperHelperTrait;

class NewsScraperService
{
    use ScraperEnginesTrait, ScraperHtmlParserTrait, ScraperHelperTrait;

    public function scrape($url, $customSelectors = [], $userId = null)
    {
        $proxy = $this->getProxyConfig($userId);
        $proxyLog = $proxy ? parse_url($proxy, PHP_URL_HOST) : "Direct";
        Log::info("ğŸš€ START SCRAPE: $url | via $proxyLog");

        $hardSites = ['jamuna.tv', 'kalerkantho.com', 'somoynews.tv', 'dailyamardesh.com']; 
        $isHardSite = false;
        foreach ($hardSites as $site) {
            if (str_contains($url, $site)) {
                $isHardSite = true;
                break;
            }
        }

        // ğŸ STEP 1: PYTHON SCRAPER
        $pythonData = $this->runPythonScraper($url, $userId);

        if ($pythonData && !empty($pythonData['body'])) {
            Log::info("âœ… Python Scraper Success");
            return [
                'title'      => $this->cleanTitle($pythonData['title'] ?? null), // ğŸ”¥ Title Cleaned
                'image'      => $this->fixVendorImages($pythonData['image'] ?? null), // ğŸ”¥ Vendor Image Fixed
                'body'       => $this->cleanHtml($pythonData['body']), 
                'source_url' => $url
            ];
        }

        Log::info("âš ï¸ Python failed. Checking fallback strategy...");

        // ğŸ˜ STEP 2: PHP HTTP REQUEST
        $htmlContent = null;

        if (!$isHardSite) {
            try {
                $htmlContent = retry(2, function () use ($url, $proxy) {
                    $timeout = $proxy ? 20 : 15; 
                    $httpRequest = Http::withHeaders($this->getRealBrowserHeaders())
                        ->timeout($timeout)
                        ->withOptions(['verify' => false, 'connect_timeout' => 10]);

                    if ($proxy) $httpRequest->withOptions(['proxy' => $proxy]);

                    $response = $httpRequest->get($url);
                    if ($response->successful()) return $response->body();
                    
                    throw new \Exception("HTTP Status: " . $response->status());
                }, 3000);
                
            } catch (\Exception $e) {
                Log::warning("PHP HTTP Failed after retries: " . $e->getMessage());
            }
        } else {
            Log::info("ğŸ›¡ï¸ Skipping PHP fallback for Hard Site (Cloudflare protected).");
        }

        // ğŸ¤– STEP 3: PUPPETEER (Last Resort)
        if (empty($htmlContent) || str_contains($htmlContent, 'Just a moment') || strlen($htmlContent) < 600) {
            Log::info("ğŸ”„ All Fast Methods Failed. Engaging Puppeteer Engine...");
            return $this->scrapeWithPuppeteer($url, $customSelectors, $userId);
        }

        // 4ï¸âƒ£ FINAL PROCESSING
        if ($htmlContent && strlen($htmlContent) > 500) {
            $scrapedData = $this->processHtml($htmlContent, $url, $customSelectors);
            
            // ğŸ”¥ Image Cleaned Here
            if (isset($scrapedData['image'])) {
                $scrapedData['image'] = $this->fixVendorImages($scrapedData['image']);
            }
            
            // ğŸ”¥ Title Cleaned Here
            if (isset($scrapedData['title'])) {
                $scrapedData['title'] = $this->cleanTitle($scrapedData['title']);
            }
            
            if (empty($scrapedData['title']) || empty($scrapedData['body'])) {
                 Log::warning("âš ï¸ Content Parsing Failed. Retrying with Puppeteer...");
                 return $this->scrapeWithPuppeteer($url, $customSelectors, $userId);
            }
            return $scrapedData;
        }

        Log::error("âŒ CRITICAL: Scrape totally failed for: $url");
        return null;
    }





}